{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nash635/nash635/blob/master/notebooks/AlphaFold.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib import rcParams\n",
        "import numpy as np\n",
        "\n",
        "# Configure Chinese font support\n",
        "rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'Microsoft YaHei', 'DejaVu Sans']\n",
        "rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# Updated model data (corrected based on search results)\n",
        "# Format: (Name, Year, Month, Total Params in B, Active Params in B, Technical Features)\n",
        "models = [\n",
        "    (\"GPT-3\", 2020, 6, 175, 175, \"Dense Transformer\"),\n",
        "    (\"PaLM\", 2022, 4, 540, 540, \"Pathways architecture\"),\n",
        "    (\"GPT-4\", 2023, 3, 1760, 1760, \"Multimodal, MoE (estimated)\"),\n",
        "    (\"LLaMA-2\", 2023, 7, 70, 70, \"Efficient pretraining, open source\"),\n",
        "    (\"Claude 3\", 2024, 3, 200, 200, \"Constitutional AI (estimated)\"),\n",
        "    (\"Gemini 1.5\", 2024, 2, 1560, 1560, \"Multimodal, 1M context (estimated)\"),\n",
        "    (\"GPT-4o\", 2024, 5, 200, 200, \"Unified multimodal (estimated)\"),\n",
        "    (\"Qwen2\", 2024, 6, 72, 72, \"Multilingual, scalable\"),\n",
        "    (\"DeepSeek-V3\", 2024, 12, 671, 37, \"MoE, efficient training\"),\n",
        "    (\"Qwen2.5\", 2025, 1, 72, 72, \"Long context + instruction tuning\"),\n",
        "    (\"Kimi k1.5\", 2025, 2, 456, 28, \"RL scaling, long2short CoT\"),\n",
        "    (\"MiniMax-01\", 2025, 2, 456, 28, \"Lightning Attention, 4M context\"),\n",
        "    (\"Ming-Omni\", 2025, 6, 456, 28, \"Unified multimodal, MoE (estimated)\"),\n",
        "    (\"Kimi K2\", 2025, 7, 1000, 32, \"MoE, Muon optimizer, agentic AI\"),\n",
        "    (\"Ming-lite-omni v1.5\", 2025, 7, 20, 3, \"Enhanced video, speech synthesis\"),\n",
        "    (\"DeepSeek-V3.1\", 2025, 8, 671, 37, \"Hybrid thinking mode, 128K context\"),\n",
        "    (\"DeepSeek-V3.2-Exp\", 2025, 9, 671, 37, \"DSA sparse attention, 50% cost cut\"),\n",
        "    (\"Ling-1T\", 2025, 10, 1000, 100, \"FP8 training, Evo-CoT (estimated)\"),\n",
        "    (\"MiniMax M2\", 2025, 10, 230, 10, \"MoE, agent+code native, 2x faster\"),\n",
        "]\n",
        "\n",
        "# Extract data\n",
        "years = [m[1] for m in models]\n",
        "months = [m[2] for m in models]\n",
        "names = [m[0] for m in models]\n",
        "total_params = [m[3] for m in models]\n",
        "active_params = [m[4] for m in models]\n",
        "features = [m[5] for m in models]\n",
        "\n",
        "# Calculate exact time positions (year + month/12)\n",
        "time_positions = [y + (m-1)/12 for y, m in zip(years, months)]\n",
        "\n",
        "# Assign colors based on release time\n",
        "colors = []\n",
        "for y, m in zip(years, months):\n",
        "    if y < 2025:\n",
        "        colors.append('#1f77b4')  # Blue: 2020-2024\n",
        "    elif m <= 5:\n",
        "        colors.append('#d62728')  # Red: 2025 Q1-Q2 early\n",
        "    elif 6 <= m <= 8:\n",
        "        colors.append('#ff7f0e')  # Orange: 2025 mid-year (Jun-Aug)\n",
        "    else:\n",
        "        colors.append('#2ca02c')  # Green: 2025 H2 (Sep-Oct)\n",
        "\n",
        "# Create figure with larger canvas\n",
        "fig, ax = plt.subplots(figsize=(20, 14))\n",
        "\n",
        "# Use log scale for y-axis (parameter size)\n",
        "# Plot bubbles with size proportional to active parameters\n",
        "bubble_sizes = [max(p * 3, 50) for p in active_params]  # Scale for visibility\n",
        "\n",
        "scatter = ax.scatter(time_positions, total_params, s=bubble_sizes, c=colors,\n",
        "                     edgecolors='black', alpha=0.7, zorder=3, linewidth=1.5)\n",
        "\n",
        "# Add annotations (adjust position to avoid overlap)\n",
        "for i, (name, time_pos, total_p, active_p, feat) in enumerate(zip(names, time_positions, total_params, active_params, features)):\n",
        "    # Model name on the right side of point\n",
        "    ax.text(time_pos + 0.08, total_p * 1.15, name,\n",
        "            va='bottom', ha='left', fontsize=9.5, fontweight='bold')\n",
        "    # Parameter info below name\n",
        "    param_text = f\"{total_p}B total, {active_p}B active\" if total_p != active_p else f\"{total_p}B params\"\n",
        "    ax.text(time_pos + 0.08, total_p * 0.92, param_text,\n",
        "            va='top', ha='left', fontsize=8, color='#555555', style='italic')\n",
        "    # Technical features below params\n",
        "    ax.text(time_pos + 0.08, total_p * 0.75, feat,\n",
        "            va='top', ha='left', fontsize=7.5, color='#666666')\n",
        "\n",
        "# Add vertical grid lines\n",
        "for year in range(2020, 2026):\n",
        "    ax.axvline(x=year, color='gray', linestyle='--', alpha=0.3, linewidth=0.8)\n",
        "\n",
        "# Set log scale for y-axis\n",
        "ax.set_yscale('log')\n",
        "\n",
        "# Formatting\n",
        "ax.set_title(\"LLM Architecture Evolution Timeline (2020-2025)\\nBubble Size = Active Parameters\",\n",
        "             fontsize=18, fontweight='bold', pad=20)\n",
        "ax.set_xlabel(\"Timeline (Year-Month)\", fontsize=14, fontweight='bold')\n",
        "ax.set_ylabel(\"Total Parameters (Billions, log scale)\", fontsize=14, fontweight='bold')\n",
        "ax.set_xlim(2019.8, 2026)\n",
        "ax.set_ylim(15, 2500)\n",
        "\n",
        "# X-axis ticks\n",
        "ax.set_xticks([2020, 2021, 2022, 2023, 2024, 2025, 2025.5, 2025.83])\n",
        "ax.set_xticklabels(['2020', '2021', '2022', '2023', '2024', '2025 Q1-Q2', '2025 Jun-Aug', '2025 Sep-Oct'],\n",
        "                   rotation=15, ha='right')\n",
        "\n",
        "# Y-axis ticks\n",
        "ax.set_yticks([20, 50, 100, 200, 500, 1000, 2000])\n",
        "ax.set_yticklabels(['20B', '50B', '100B', '200B', '500B', '1T', '2T'])\n",
        "\n",
        "ax.grid(True, axis='both', linestyle='--', alpha=0.3)\n",
        "\n",
        "# Legend\n",
        "legend_elements = [\n",
        "    mpatches.Patch(color='#1f77b4', label='2020-2024'),\n",
        "    mpatches.Patch(color='#d62728', label='2025 Q1-Q2 Early (Jan-May)'),\n",
        "    mpatches.Patch(color='#ff7f0e', label='2025 Mid-Year (Jun-Aug)'),\n",
        "    mpatches.Patch(color='#2ca02c', label='2025 H2 (Sep-Oct)')\n",
        "]\n",
        "ax.legend(handles=legend_elements, loc='upper left', fontsize=11)\n",
        "\n",
        "# Add technical trends annotation\n",
        "trend_text = \"\"\"Key Technical Trends:\n",
        "• MoE sparse activation becomes mainstream\n",
        "• FP8 mixed-precision training breakthrough\n",
        "• Inference efficiency optimization (RL+new optimizers)\n",
        "• Long context capability increase (4M tokens)\n",
        "• Lightning/DSA attention mechanisms\n",
        "• Unified multimodal architecture (understand+generate)\n",
        "• Agentic AI as new competitive arena\n",
        "• Cost efficiency revolution (10B active ≈ 230B total)\"\"\"\n",
        "\n",
        "ax.text(0.02, 0.98, trend_text, transform=ax.transAxes,\n",
        "        fontsize=9.5, bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.65),\n",
        "        verticalalignment='top', linespacing=1.6)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n=== Corrected 2025 LLM Technology Innovation Timeline ===\\n\")\n",
        "print(\"【IMPORTANT CORRECTIONS】\")\n",
        "print(\"• DeepSeek-V3.1: August 2025 (not January)\")\n",
        "print(\"• DeepSeek-V3.2-Exp: September 29, 2025 (not March)\")\n",
        "print(\"• Kimi K2: July 11, 2025 ✓\")\n",
        "print(\"• MiniMax M2: October 27, 2025 ✓\")\n",
        "\n",
        "print(\"\\n【Q1-Q2 Early: Jan-May】Foundation Enhancement\")\n",
        "print(\"1. Qwen2.5 (Jan): Long context + instruction tuning\")\n",
        "print(\"2. Kimi k1.5 (Feb): RL scaling breakthrough, long2short CoT\")\n",
        "print(\"3. MiniMax-01 (Feb): Lightning Attention, 4M ultra-long context\")\n",
        "\n",
        "print(\"\\n【Mid-Year: Jun-Aug】Multimodal + Agentic Breakthrough\")\n",
        "print(\"4. Ming-Omni (Jun): Unified multimodal (perception+generation)\")\n",
        "print(\"5. Kimi K2 (Jul 11):\")\n",
        "print(\"   - 1T total params, 32B active MoE architecture\")\n",
        "print(\"   - MuonClip optimizer: ultra-large-scale training stability\")\n",
        "print(\"   - Designed for Agentic AI\")\n",
        "print(\"   - 15.5T tokens, zero loss spike\")\n",
        "\n",
        "print(\"6. Ming-lite-omni v1.5 (Jul): 20.3B total, 3B active\")\n",
        "print(\"7. DeepSeek-V3.1 (Aug 21):\")\n",
        "print(\"   - Hybrid thinking mode: thinking + non-thinking\")\n",
        "print(\"   - 128K context window\")\n",
        "print(\"   - Enhanced tool calling and agent capabilities\")\n",
        "\n",
        "print(\"\\n【H2: Sep-Oct】Trillion-Parameter + Extreme Efficiency\")\n",
        "print(\"8. DeepSeek-V3.2-Exp (Sep 29):\")\n",
        "print(\"   - DSA (DeepSeek Sparse Attention)\")\n",
        "print(\"   - 50% cost reduction vs V3.1\")\n",
        "print(\"   - Experimental model for next-gen architecture\")\n",
        "\n",
        "print(\"9. Ling-1T (Oct 9): 1T params, FP8 training, Evo-CoT\")\n",
        "print(\"10. MiniMax M2 (Oct 27):\")\n",
        "print(\"    - MoE 230B total, only 10B active\")\n",
        "print(\"    - 2x speed of Claude Sonnet 4.5\")\n",
        "print(\"    - Cost only 8%\")\n",
        "print(\"    - 205K context window\")\n",
        "print(\"    - #1 open-source model on Artificial Analysis\")\n",
        "\n",
        "print(\"\\n【Core Technology Evolution】\")\n",
        "print(\"✓ Jun: Multimodal unification (understand+generate)\")\n",
        "print(\"✓ Jul: Agentic AI becomes standard, new optimizers break training bottlenecks\")\n",
        "print(\"✓ Aug: Hybrid thinking modes mature\")\n",
        "print(\"✓ Sep-Oct: Trillion-parameter + FP8 training mature, revolutionary cost efficiency\")\n",
        "print(\"✓ Full Year: MoE sparse activation, long context, code gen continue to evolve\")\n",
        "print(\"✓ Trend: From dialogue to action, from uni-modal to omni-modal, from capability to efficiency\")"
      ],
      "metadata": {
        "id": "gKkKWKJ1Do7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5g8SVc8EQiJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "AlphaFold.ipynb",
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}